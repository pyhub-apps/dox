use anyhow::Result;
use clap::Args;
use std::path::PathBuf;

/// AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  ìƒì„± (OpenAI ë˜ëŠ” Claude)
///
/// AI ì œê³µì—…ì²´ ì„¤ì •:
///   â€¢ OpenAI: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •
///   â€¢ Claude: ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •
///
/// ì˜ˆì‹œ:
///   # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
///   dox generate -p "Rust í”„ë¡œê·¸ë˜ë° ì…ë¬¸" -t blog
///   
///   # GPT-4ë¡œ ë³´ê³ ì„œ ìƒì„±
///   dox generate -p "2025ë…„ ì‹œì¥ ë¶„ì„" -t report --model gpt-4
///   
///   # Claudeë¡œ ì´ë©”ì¼ ìƒì„±
///   dox generate -p "í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ ê³µìœ " -t email --model claude-3-5-sonnet-20241022
#[derive(Args, Debug)]
pub struct GenerateArgs {
    /// ìƒì„± í”„ë¡¬í”„íŠ¸
    #[arg(short, long)]
    pub prompt: String,

    /// ìƒì„±í•  ì½˜í…ì¸  ìœ í˜•
    ///
    /// â€¢ blog: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸
    /// â€¢ documentation: ê¸°ìˆ  ë¬¸ì„œ
    /// â€¢ report: ë³´ê³ ì„œ
    /// â€¢ summary: ìš”ì•½
    /// â€¢ email: ì´ë©”ì¼
    /// â€¢ proposal: ì œì•ˆì„œ
    /// â€¢ custom: ì‚¬ìš©ì ì •ì˜
    #[arg(short = 't', long, value_enum, default_value = "custom")]
    pub content_type: ContentType,

    /// ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ í‘œì¤€ì¶œë ¥)
    #[arg(short, long, value_name = "íŒŒì¼")]
    pub output: Option<PathBuf>,

    /// ì‚¬ìš©í•  AI ëª¨ë¸
    #[arg(long, default_value = "gpt-3.5-turbo")]
    pub model: String,

    /// ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜
    #[arg(long, default_value = "2000")]
    pub max_tokens: usize,

    /// ì°½ì˜ì„± ìˆ˜ì¤€ (0.0-1.0)
    #[arg(long, default_value = "0.7")]
    pub temperature: f32,

    /// AI ì œê³µì—…ì²´ (ëª¨ë¸ì—ì„œ ìë™ ê°ì§€)
    #[arg(long, value_enum)]
    pub provider: Option<AIProvider>,

    /// API í‚¤ (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê°€ëŠ¥)
    #[arg(long)]
    pub api_key: Option<String>,

    /// ìƒì„±í•  ì½˜í…ì¸  ì–¸ì–´
    #[arg(long, default_value = "ko")]
    pub language: String,

    /// ëŒ€ìƒ ë…ì
    #[arg(long, default_value = "ì¼ë°˜")]
    pub audience: String,

    /// ê¸€ì˜ í†¤
    #[arg(long, default_value = "ì „ë¬¸ì ")]
    pub tone: String,
}

#[derive(Debug, Clone, Copy, clap::ValueEnum)]
pub enum ContentType {
    Blog,
    Documentation,
    Report,
    Summary,
    Email,
    Proposal,
    Custom,
}

#[derive(Debug, Clone, Copy, clap::ValueEnum)]
pub enum AIProvider {
    OpenAI,
    Claude,
}

pub async fn execute(args: GenerateArgs) -> Result<()> {
    use dox_core::generate::{ContentGenerator, GenerationRequest, openai::OpenAIProvider, claude::ClaudeProvider};
    use dox_core::utils::ui;
    use std::fs;

    ui::print_info(&format!(
        "{} ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...",
        args.content_type.as_str_ko()
    ));

    // Create generation request
    let request = GenerationRequest {
        prompt: args.prompt.clone(),
        content_type: convert_content_type(args.content_type),
        model: args.model.clone(),
        max_tokens: args.max_tokens,
        temperature: args.temperature,
        language: args.language.clone(),
        audience: args.audience.clone(),
        tone: args.tone.clone(),
        context: None,
        stream: false, // TODO: Implement streaming
        provider_params: std::collections::HashMap::new(),
    };

    // Create AI provider
    let provider = match detect_provider(&args.model) {
        "openai" => {
            // Try to get API key from args, environment, or config
            let api_key = get_api_key("openai", args.api_key.as_deref())?;
            Box::new(OpenAIProvider::new(api_key)) as Box<dyn ContentGenerator>
        }
        "claude" => {
            // Try to get API key from args, environment, or config
            let api_key = get_api_key("claude", args.api_key.as_deref())?;
            Box::new(ClaudeProvider::new(api_key)) as Box<dyn ContentGenerator>
        }
        provider_name => {
            return Err(anyhow::anyhow!("ì§€ì›ë˜ì§€ ì•ŠëŠ” AI ì œê³µì—…ì²´: {}", provider_name));
        }
    };

    // Show generation info
    ui::print_info(&format!(
        "ğŸ¤– {} ëª¨ë¸ë¡œ {} ì½˜í…ì¸  ìƒì„± ì¤‘...",
        request.model,
        request.content_type.as_str()
    ));

    // Generate content
    let response = provider.generate(&request).await?;

    // Show token usage if available
    if let Some(usage) = &response.usage {
        ui::print_info(&format!(
            "ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {} (í”„ë¡¬í”„íŠ¸: {}, ì™„ì„±: {})",
            usage.total_tokens, usage.prompt_tokens, usage.completion_tokens
        ));
    }

    // Output content
    if let Some(mut output_path) = args.output {
        // Add appropriate extension if not present
        if output_path.extension().is_none() {
            let extension = get_file_extension(args.content_type);
            output_path = output_path.with_extension(extension);
        }
        
        // Save to file
        fs::write(&output_path, &response.content)?;
        ui::print_success(&format!(
            "âœ… ì½˜í…ì¸ ê°€ ìƒì„±ë˜ì–´ {}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            output_path.display()
        ));
    } else {
        // Print to stdout
        println!("\n{}", response.content);
    }

    Ok(())
}

/// Convert CLI content type to core content type
fn convert_content_type(cli_type: ContentType) -> dox_core::generate::ContentType {
    match cli_type {
        ContentType::Blog => dox_core::generate::ContentType::Blog,
        ContentType::Documentation => dox_core::generate::ContentType::Documentation,
        ContentType::Report => dox_core::generate::ContentType::Report,
        ContentType::Summary => dox_core::generate::ContentType::Summary,
        ContentType::Email => dox_core::generate::ContentType::Email,
        ContentType::Proposal => dox_core::generate::ContentType::Proposal,
        ContentType::Custom => dox_core::generate::ContentType::Custom,
    }
}

/// Detect AI provider from model name
fn detect_provider(model: &str) -> &str {
    if model.starts_with("gpt-") {
        "openai"
    } else if model.starts_with("claude-") {
        "claude"
    } else {
        "openai" // Default to OpenAI
    }
}

/// Get API key from various sources
fn get_api_key(provider: &str, cli_key: Option<&str>) -> Result<String> {
    // Priority: CLI arg > environment variable > config file
    if let Some(key) = cli_key {
        return Ok(key.to_string());
    }

    let env_var = match provider {
        "openai" => "OPENAI_API_KEY",
        "claude" => "ANTHROPIC_API_KEY",
        _ => return Err(anyhow::anyhow!("ì•Œ ìˆ˜ ì—†ëŠ” ì œê³µì—…ì²´: {}", provider)),
    };

    std::env::var(env_var)
        .map_err(|_| anyhow::anyhow!("{} í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” --api-key ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤", env_var))
}

/// Get appropriate file extension for content type
fn get_file_extension(content_type: ContentType) -> &'static str {
    match content_type {
        ContentType::Blog => "md",
        ContentType::Documentation => "md",
        ContentType::Report => "md",
        ContentType::Summary => "txt",
        ContentType::Email => "txt",
        ContentType::Proposal => "md",
        ContentType::Custom => "txt",
    }
}

impl ContentType {
    fn as_str(&self) -> &str {
        match self {
            ContentType::Blog => "blog",
            ContentType::Documentation => "documentation",
            ContentType::Report => "report",
            ContentType::Summary => "summary",
            ContentType::Email => "email",
            ContentType::Proposal => "proposal",
            ContentType::Custom => "custom",
        }
    }

    fn as_str_ko(&self) -> &str {
        match self {
            ContentType::Blog => "ë¸”ë¡œê·¸",
            ContentType::Documentation => "ë¬¸ì„œ",
            ContentType::Report => "ë³´ê³ ì„œ",
            ContentType::Summary => "ìš”ì•½",
            ContentType::Email => "ì´ë©”ì¼",
            ContentType::Proposal => "ì œì•ˆì„œ",
            ContentType::Custom => "ì‚¬ìš©ì ì •ì˜",
        }
    }
}
